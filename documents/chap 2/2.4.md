# Giai Ä‘oáº¡n 2: Ná»n táº£ng ToÃ¡n & Thá»‘ng kÃª
## BÃ i 2.4: Äáº¡i sá»‘ tuyáº¿n tÃ­nh (Pháº§n 4) - Trá»‹ riÃªng, Vector riÃªng & SVD

### **ğŸ¯ Má»¥c tiÃªu bÃ i há»c:**
1.  Hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a trá»±c quan cá»§a **Trá»‹ riÃªng (Eigenvalues)** vÃ  **Vector riÃªng (Eigenvectors)**.
2.  Náº¯m báº¯t táº§m quan trá»ng cá»§a chÃºng trong viá»‡c phÃ¢n tÃ­ch cÃ¡c phÃ©p biáº¿n Ä‘á»•i vÃ  dá»¯ liá»‡u.
3.  LÃ m quen vá»›i hai ká»¹ thuáº­t phÃ¢n rÃ£ ma tráº­n máº¡nh máº½: **Eigendecomposition** vÃ  **Singular Value Decomposition (SVD)**.
4.  Sá»­ dá»¥ng NumPy Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c giÃ¡ trá»‹ nÃ y.

---

### **1. Ã nghÄ©a trá»±c quan cá»§a Trá»‹ riÃªng & Vector riÃªng**

HÃ£y nhá»› láº¡i ráº±ng má»™t ma tráº­n lÃ  má»™t phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh. Khi báº¡n nhÃ¢n má»™t ma tráº­n `A` vá»›i má»™t vector `v`, vector `v` sáº½ bá»‹ biáº¿n Ä‘á»•i (xoay, co giÃ£n, ...).

Tuy nhiÃªn, Ä‘á»‘i vá»›i má»™t ma tráº­n `A` báº¥t ká»³, luÃ´n tá»“n táº¡i nhá»¯ng **vector riÃªng (eigenvectors)** ráº¥t Ä‘áº·c biá»‡t. Khi bá»‹ biáº¿n Ä‘á»•i bá»Ÿi `A`, cÃ¡c vector nÃ y **khÃ´ng há» thay Ä‘á»•i phÆ°Æ¡ng**, chÃºng chá»‰ bá»‹ co giÃ£n dÃ i ra hoáº·c ngáº¯n láº¡i.

Há»‡ sá»‘ co giÃ£n Ä‘Ã³ chÃ­nh lÃ  **trá»‹ riÃªng (eigenvalue)** tÆ°Æ¡ng á»©ng.

**PhÆ°Æ¡ng trÃ¬nh cá»‘t lÃµi:**
$$A\mathbf{v} = \lambda\mathbf{v}$$
Trong Ä‘Ã³:
* **A:** lÃ  má»™t ma tráº­n vuÃ´ng.
* **v:** lÃ  má»™t vector riÃªng (eigenvector).
* **Î»:** lÃ  má»™t trá»‹ riÃªng (eigenvalue).

**Analogy:** TÆ°á»Ÿng tÆ°á»£ng má»™t quáº£ Ä‘á»‹a cáº§u Ä‘ang quay. Má»i Ä‘iá»ƒm trÃªn bá» máº·t Ä‘á»u thay Ä‘á»•i hÆ°á»›ng, ngoáº¡i trá»« cÃ¡c Ä‘iá»ƒm náº±m trÃªn **trá»¥c quay**. Trá»¥c quay nÃ y chÃ­nh lÃ  phÆ°Æ¡ng cá»§a **vector riÃªng**. CÃ¡c Ä‘iá»ƒm trÃªn Ä‘Ã³ chá»‰ di chuyá»ƒn dá»c theo trá»¥c chá»© khÃ´ng Ä‘á»•i hÆ°á»›ng. 

---

### **2. Táº§m quan trá»ng trong Khoa há»c Dá»¯ liá»‡u**

Trá»‹ riÃªng vÃ  vector riÃªng tiáº¿t lá»™ nhá»¯ng "trá»¥c" hay "hÆ°á»›ng" quan trá»ng nháº¥t cá»§a dá»¯ liá»‡u.

* **PhÃ¢n tÃ­ch ThÃ nh pháº§n chÃ­nh (Principal Component Analysis - PCA):** ÄÃ¢y lÃ  á»©ng dá»¥ng quan trá»ng nháº¥t. PCA lÃ  má»™t ká»¹ thuáº­t giáº£m chiá»u dá»¯ liá»‡u. NÃ³ hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch tÃ¬m cÃ¡c vector riÃªng cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai cá»§a dá»¯ liá»‡u.
    * **Vector riÃªng** cÃ³ trá»‹ riÃªng lá»›n nháº¥t chÃ­nh lÃ  **thÃ nh pháº§n chÃ­nh thá»© nháº¥t (PC1)** - hÆ°á»›ng mÃ  dá»¯ liá»‡u cÃ³ phÆ°Æ¡ng sai (biáº¿n thiÃªn) lá»›n nháº¥t.
    * PC2 lÃ  hÆ°á»›ng cÃ³ phÆ°Æ¡ng sai lá»›n thá»© hai vÃ  vuÃ´ng gÃ³c vá»›i PC1, v.v.
    Báº±ng cÃ¡ch chá»‰ giá»¯ láº¡i má»™t vÃ i thÃ nh pháº§n chÃ­nh Ä‘áº§u tiÃªn, chÃºng ta cÃ³ thá»ƒ nÃ©n dá»¯ liá»‡u mÃ  váº«n giá»¯ Ä‘Æ°á»£c pháº§n lá»›n thÃ´ng tin quan trá»ng.

---

### **3. PhÃ¢n rÃ£ Trá»‹ riÃªng (Eigendecomposition)**

ÄÃ¢y lÃ  ká»¹ thuáº­t phÃ¢n rÃ£ má»™t ma tráº­n thÃ nh tÃ­ch cá»§a cÃ¡c trá»‹ riÃªng vÃ  vector riÃªng cá»§a nÃ³.
$$A = Q \Lambda Q^{-1}$$
* **Q:** lÃ  ma tráº­n chá»©a cÃ¡c vector riÃªng cá»§a A á»Ÿ cÃ¡c cá»™t.
* **Î› (Lambda):** lÃ  ma tráº­n Ä‘Æ°á»ng chÃ©o chá»©a cÃ¡c trá»‹ riÃªng tÆ°Æ¡ng á»©ng.

**Háº¡n cháº¿:** PhÃ¢n rÃ£ trá»‹ riÃªng chá»‰ Ã¡p dá»¥ng Ä‘Æ°á»£c cho má»™t sá»‘ loáº¡i ma tráº­n vuÃ´ng nháº¥t Ä‘á»‹nh.

---

### **4. PhÃ¢n rÃ£ GiÃ¡ trá»‹ suy biáº¿n (Singular Value Decomposition - SVD)**

SVD lÃ  má»™t ká»¹ thuáº­t tá»•ng quÃ¡t vÃ  máº¡nh máº½ hÆ¡n ráº¥t nhiá»u. NÃ³ cÃ³ thá»ƒ phÃ¢n rÃ£ **báº¥t ká»³ ma tráº­n nÃ o** (khÃ´ng cáº§n pháº£i lÃ  ma tráº­n vuÃ´ng).
$$A = U \Sigma V^T$$
* **U, V:** lÃ  cÃ¡c ma tráº­n trá»±c giao.
* **Î£ (Sigma):** lÃ  ma tráº­n Ä‘Æ°á»ng chÃ©o chá»©a cÃ¡c **giÃ¡ trá»‹ suy biáº¿n (singular values)**.

SVD lÃ  ná»n táº£ng toÃ¡n há»c Ä‘áº±ng sau vÃ´ sá»‘ á»©ng dá»¥ng: PCA, cÃ¡c há»‡ thá»‘ng gá»£i Ã½ sáº£n pháº©m (recommendation systems), nÃ©n áº£nh, vÃ  nhiá»u thuáº­t toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn.

---

### **5. Thá»±c hÃ nh vá»›i NumPy**

    import numpy as np

    # Ma tráº­n vÃ­ dá»¥
    A = np.array([[4, 2],
                  [1, 3]])

    # 1. TÃ­nh Trá»‹ riÃªng vÃ  Vector riÃªng
    eigenvalues, eigenvectors = np.linalg.eig(A)

    print("--- Trá»‹ riÃªng & Vector riÃªng ---")
    print("Trá»‹ riÃªng (Î»):", eigenvalues)
    print("Vector riÃªng (v) (má»—i cá»™t lÃ  má»™t vector):")
    print(eigenvectors)

    # 2. Thá»±c hiá»‡n PhÃ¢n rÃ£ SVD
    U, S, VT = np.linalg.svd(A)

    print("\n--- PhÃ¢n rÃ£ SVD ---")
    print("Ma tráº­n U:\n", U)
    print("GiÃ¡ trá»‹ suy biáº¿n (Î£):", S) # NumPy tráº£ vá» dÆ°á»›i dáº¡ng vector
    print("Ma tráº­n V^T:\n", VT)

---

### **âœï¸ BÃ i thá»±c hÃ nh:**

1.  **Kiá»ƒm chá»©ng phÆ°Æ¡ng trÃ¬nh Eigen:**
    * Sá»­ dá»¥ng ma tráº­n `A`, cÃ¡c `eigenvalues` vÃ  `eigenvectors` Ä‘Ã£ tÃ­nh á»Ÿ trÃªn.
    * Láº¥y vector riÃªng Ä‘áº§u tiÃªn (`v1 = eigenvectors[:, 0]`) vÃ  trá»‹ riÃªng Ä‘áº§u tiÃªn (`lambda1 = eigenvalues[0]`).
    * HÃ£y kiá»ƒm tra xem `A @ v1` cÃ³ báº±ng (hoáº·c xáº¥p xá»‰ báº±ng) `lambda1 * v1` hay khÃ´ng. In cáº£ hai káº¿t quáº£ ra Ä‘á»ƒ so sÃ¡nh.

2.  **á»¨ng dá»¥ng SVD Ä‘á»ƒ nÃ©n áº£nh (Conceptual & Practical):**
    * ÄÃ¢y lÃ  má»™t bÃ i táº­p ráº¥t thÃº vá»‹ Ä‘á»ƒ tháº¥y sá»©c máº¡nh cá»§a SVD.
    * **BÆ°á»›c 1 (Load áº£nh):** DÃ¹ng code sau Ä‘á»ƒ load má»™t áº£nh máº«u cÃ³ sáºµn vÃ  chuyá»ƒn nÃ³ thÃ nh áº£nh xÃ¡m.
        
            from sklearn.datasets import fetch_olivetti_faces
            import matplotlib.pyplot as plt

            # Load dataset áº£nh khuÃ´n máº·t
            faces = fetch_olivetti_faces()
            image = faces.images[0] # Láº¥y áº£nh Ä‘áº§u tiÃªn

            print(f"KÃ­ch thÆ°á»›c áº£nh gá»‘c: {image.shape}")
            plt.imshow(image, cmap='gray')
            plt.title("áº¢nh Gá»‘c")
            plt.show()

    * **BÆ°á»›c 2 (Thá»±c hiá»‡n SVD):**
        * Thá»±c hiá»‡n SVD trÃªn ma tráº­n `image`: `U, S, VT = np.linalg.svd(image)`.

    * **BÆ°á»›c 3 (NÃ©n vÃ  TÃ¡i táº¡o):**
        * Viáº¿t má»™t vÃ²ng láº·p `for` vá»›i cÃ¡c giÃ¡ trá»‹ `k` trong `[5, 15, 30]`. `k` lÃ  sá»‘ lÆ°á»£ng giÃ¡ trá»‹ suy biáº¿n (thÃ nh pháº§n chÃ­nh) báº¡n muá»‘n giá»¯ láº¡i.
        * BÃªn trong vÃ²ng láº·p, hÃ£y tÃ¡i táº¡o láº¡i áº£nh chá»‰ vá»›i `k` thÃ nh pháº§n:
            * Táº¡o ma tráº­n Sigma má»›i: `Sigma_k = np.zeros(image.shape)`
            * Äiá»n `k` giÃ¡ trá»‹ suy biáº¿n Ä‘áº§u tiÃªn vÃ o: `Sigma_k[:k, :k] = np.diag(S[:k])`
            * TÃ¡i táº¡o áº£nh: `reconstructed_image = U @ Sigma_k @ VT`
    * **BÆ°á»›c 4 (Hiá»ƒn thá»‹):** DÃ¹ng `plt.imshow()` Ä‘á»ƒ hiá»ƒn thá»‹ cÃ¡c áº£nh Ä‘Æ°á»£c tÃ¡i táº¡o vá»›i cÃ¡c giÃ¡ trá»‹ `k` khÃ¡c nhau vÃ  so sÃ¡nh chÃºng vá»›i áº£nh gá»‘c. Báº¡n sáº½ tháº¥y cháº¥t lÆ°á»£ng áº£nh tÄƒng dáº§n khi `k` tÄƒng.