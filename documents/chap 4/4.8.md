# Giai đoạn 4: Nhập môn Học Máy và các Nguyên lý Cốt lõi
## Bài 4.8: Đánh giá Mô hình Nâng cao (Cross-Validation & Hyperparameter Tuning)

### **🎯 Mục tiêu bài học:**
1.  Hiểu được hạn chế của việc chỉ dùng một cặp Train-Test Split duy nhất.
2.  Nắm vững kỹ thuật **Kiểm định chéo (Cross-Validation)**, "tiêu chuẩn vàng" để đánh giá mô hình.
3.  Hiểu sự khác biệt giữa **tham số (parameters)** và **siêu tham số (hyperparameters)**.
4.  Học cách tự động tìm kiếm siêu tham số tốt nhất bằng **Grid Search**.

---

### **Bối cảnh & Tầm quan trọng**

Ở các bài trước, chúng ta chia dữ liệu thành một cặp train/test. Nhưng điều gì sẽ xảy ra nếu lần chia đó của chúng ta là "may mắn" hoặc "xui xẻo"? Ví dụ, tập test vô tình chứa toàn các trường hợp dễ đoán, làm cho điểm số của mô hình cao giả tạo. Hoặc ngược lại.

**Kiểm định chéo (Cross-Validation)** ra đời để giải quyết vấn đề này, cung cấp một cách đánh giá hiệu năng mô hình ổn định và đáng tin cậy hơn. Sau khi có một phương pháp đánh giá đáng tin cậy, chúng ta có thể tự tin đi tìm phiên bản tốt nhất của mô hình thông qua việc **tinh chỉnh siêu tham số (Hyperparameter Tuning)**.

---

### **Lý thuyết Cốt lõi & Triển khai**

#### **1. Kiểm định chéo K-Fold (K-Fold Cross-Validation)**

* **Ý tưởng:** Thay vì chỉ chia dữ liệu một lần, chúng ta sẽ chia và huấn luyện mô hình nhiều lần, sau đó lấy kết quả trung bình.
* **Quy trình:**
    1.  Xáo trộn và chia tập dữ liệu huấn luyện thành **K** "phần" (folds) bằng nhau (ví dụ: K=5).
    2.  Thực hiện vòng lặp K lần. Ở mỗi lần lặp:
        * Lấy 1 phần ra làm **tập thẩm định (validation set)**.
        * Dùng K-1 phần còn lại làm **tập huấn luyện (training set)**.
        * Huấn luyện mô hình và đánh giá trên tập thẩm định.
    3.  Kết quả cuối cùng là **trung bình và độ lệch chuẩn** của các điểm số thu được sau K lần lặp. 

* **Lợi ích:**
    * **Đánh giá ổn định:** Kết quả ít phụ thuộc vào sự may rủi của một lần chia.
    * **Tận dụng dữ liệu:** Mọi điểm dữ liệu đều được dùng để cả huấn luyện và thẩm định.


    from sklearn.model_selection import cross_val_score
    from sklearn.ensemble import RandomForestClassifier

    # Giả sử X_train_processed và y_train đã có
    model = RandomForestClassifier(random_state=42)

    # Thực hiện kiểm định chéo 5-fold
    # cv=5: chia thành 5 phần
    # scoring='accuracy': chỉ số đánh giá là accuracy
    scores = cross_val_score(model, X_train_processed, y_train, cv=5, scoring='accuracy')

    print("--- Kết quả Cross-Validation ---")
    print(f"Điểm Accuracy của 5 lần chạy: {scores}")
    print(f"Accuracy Trung bình: {scores.mean():.4f}")
    print(f"Độ lệch chuẩn: {scores.std():.4f}")

#### **2. Siêu tham số (Hyperparameters) vs. Tham số (Parameters)**

* **Tham số (Parameters):** Là những giá trị mà mô hình **tự học được** từ dữ liệu trong quá trình huấn luyện `.fit()`.
    * *Ví dụ:* Các trọng số `w` và `b` trong Hồi quy tuyến tính, các hệ số trong Hồi quy Logistic.

* **Siêu tham số (Hyperparameters):** Là những giá trị mà **chúng ta, những người xây dựng mô hình, phải tự thiết lập trước khi** quá trình huấn luyện bắt đầu.
    * *Ví dụ:* `max_depth` (độ sâu tối đa) của Cây quyết định, `n_estimators` (số lượng cây) trong Random Forest, `learning_rate` trong Gradient Descent.

Việc tìm ra bộ siêu tham số tốt nhất là cực kỳ quan trọng để tối ưu hóa hiệu năng mô hình.

#### **3. Tinh chỉnh Siêu tham số với Grid Search**

* **Ý tưởng:** Thay vì thử từng giá trị một cách thủ công, Grid Search sẽ tự động thử **tất cả các tổ hợp có thể có** của các siêu tham số mà bạn cung cấp.
* **Quy trình:**
    1.  Định nghĩa một "lưới" (grid) các siêu tham số bạn muốn thử.
    2.  `GridSearchCV` sẽ sử dụng Kiểm định chéo (Cross-Validation) để đánh giá hiệu năng của mô hình với mỗi tổ hợp siêu tham số.
    3.  Cuối cùng, nó sẽ cho bạn biết tổ hợp nào là tốt nhất.


    from sklearn.model_selection import GridSearchCV

    # 1. Định nghĩa lưới siêu tham số để thử
    param_grid = {
        'n_estimators': [50, 100, 200],      # Số lượng cây
        'max_depth': [None, 10, 20],         # Độ sâu tối đa
        'min_samples_split': [2, 5, 10]    # Số mẫu tối thiểu để chia nhánh
    }

    # 2. Khởi tạo GridSearchCV
    # estimator: mô hình cần tinh chỉnh
    # param_grid: lưới siêu tham số
    # cv=5: dùng kiểm định chéo 5-fold
    # n_jobs=-1: sử dụng tất cả các nhân CPU để chạy song song
    grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                               param_grid=param_grid,
                               cv=5,
                               n_jobs=-1,
                               scoring='accuracy')

    # 3. Chạy tìm kiếm (quá trình này có thể mất vài phút)
    grid_search.fit(X_train_processed, y_train)

    print("\n--- Kết quả Grid Search ---")
    print(f"Bộ siêu tham số tốt nhất tìm được: {grid_search.best_params_}")
    print(f"Accuracy tốt nhất trên tập validation: {grid_search.best_score_:.4f}")

---

### **✍️ Bài thực hành:**

Sử dụng `GridSearchCV` và mô hình `LogisticRegression`.

1.  **Import:** Import `LogisticRegression` từ `sklearn.linear_model`.
2.  **Tạo lưới Siêu tham số:**
    * `LogisticRegression` có một siêu tham số quan trọng là `C`, đây là tham số điều khiển độ mạnh của Regularization (giá trị `C` nhỏ hơn nghĩa là regularization mạnh hơn).
    * Hãy tạo một `param_grid` để thử các giá trị `C` sau: `[0.01, 0.1, 1, 10, 100]`.
    * Một siêu tham số khác là `penalty`, có thể là `'l1'` hoặc `'l2'`. Hãy thêm nó vào `param_grid`. **Lưu ý:** penalty `'l1'` chỉ hoạt động với `solver='liblinear'`.
3.  **Chạy Grid Search:**
    * Khởi tạo `GridSearchCV` với mô hình `LogisticRegression(solver='liblinear', random_state=42)`, `param_grid` bạn vừa tạo, và `cv=5`.
    * Huấn luyện nó trên `X_train_processed` và `y_train`.
4.  **In kết quả:**
    * In ra `best_params_` và `best_score_` mà Grid Search đã tìm được.