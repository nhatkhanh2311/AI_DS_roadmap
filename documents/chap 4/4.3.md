# Giai ƒëo·∫°n 4: Nh·∫≠p m√¥n H·ªçc M√°y v√† c√°c Nguy√™n l√Ω C·ªët l√µi
## B√†i 4.3: M√£ h√≥a D·ªØ li·ªáu H·∫°ng m·ª•c & Chu·∫©n h√≥a ƒê·∫∑c tr∆∞ng

### **üéØ M·ª•c ti√™u b√†i h·ªçc:**
1.  Ph√¢n t√≠ch s√¢u c√°c k·ªπ thu·∫≠t m√£ h√≥a d·ªØ li·ªáu h·∫°ng m·ª•c: **Label Encoding** v√† **One-Hot Encoding**.
2.  Hi·ªÉu r√µ n·ªÅn t·∫£ng to√°n h·ªçc v√† s·ª± ƒë√°nh ƒë·ªïi c·ªßa hai ph∆∞∆°ng ph√°p chu·∫©n h√≥a ch√≠nh: **Standardization** v√† **Normalization**.
3.  Tri·ªÉn khai m·ªôt quy tr√¨nh ti·ªÅn x·ª≠ l√Ω ho√†n ch·ªânh v√† an to√†n b·∫±ng `ColumnTransformer` c·ªßa Scikit-learn.

---

### **B·ªëi c·∫£nh & T·∫ßm quan tr·ªçng**

C√°c m√¥ h√¨nh h·ªçc m√°y v·ªÅ b·∫£n ch·∫•t l√† c√°c h√†m to√°n h·ªçc; ch√∫ng ch·ªâ "hi·ªÉu" ƒë∆∞·ª£c c√°c con s·ªë. B√†i h·ªçc n√†y gi·∫£i quy·∫øt hai v·∫•n ƒë·ªÅ c·ªët l√µi ƒë·ªÉ "d·ªãch" d·ªØ li·ªáu th√¥ sang ng√¥n ng·ªØ c·ªßa m√¥ h√¨nh:

1.  **D·ªØ li·ªáu h·∫°ng m·ª•c:** L√†m th·∫ø n√†o ƒë·ªÉ bi·ªÉu di·ªÖn c√°c gi√° tr·ªã nh∆∞ 'male', 'female' hay 'Hanoi' d∆∞·ªõi d·∫°ng s·ªë m√† kh√¥ng l√†m m√¥ h√¨nh hi·ªÉu sai?
2.  **S·ª± kh√°c bi·ªát v·ªÅ thang ƒëo:** L√†m th·∫ø n√†o ƒë·ªÉ c√°c ƒë·∫∑c tr∆∞ng nh∆∞ `Tu·ªïi` (thang ƒëo 0-80) v√† `L∆∞∆°ng` (thang ƒëo h√†ng ch·ª•c tri·ªáu) c√≥ th·ªÉ "c·∫°nh tranh" c√¥ng b·∫±ng trong m√¥ h√¨nh m√† kh√¥ng c√≥ ƒë·∫∑c tr∆∞ng n√†o b·ªã l·∫•n √°t ch·ªâ v√¨ gi√° tr·ªã c·ªßa n√≥ l·ªõn h∆°n?

Vi·ªác x·ª≠ l√Ω ƒë√∫ng hai v·∫•n ƒë·ªÅ n√†y l√† c·ª±c k·ª≥ quan tr·ªçng, ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn hi·ªáu nƒÉng v√† ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh.

---

### **L√Ω thuy·∫øt C·ªët l√µi & N·ªÅn t·∫£ng To√°n h·ªçc**

#### **1. M√£ h√≥a D·ªØ li·ªáu H·∫°ng m·ª•c (Categorical Encoding)**

##### **a. One-Hot Encoding**
* **√ù t∆∞·ªüng:** Bi·∫øn m·ªôt c·ªôt ch·ª©a `k` h·∫°ng m·ª•c th√†nh `k` c·ªôt nh·ªã ph√¢n (0/1) m·ªõi.
* **C∆° s·ªü l√Ω thuy·∫øt:** K·ªπ thu·∫≠t n√†y bi·ªÉu di·ªÖn m·ªói h·∫°ng m·ª•c nh∆∞ m·ªôt vector ƒë∆°n v·ªã tr·ª±c giao trong kh√¥ng gian `k` chi·ªÅu (`S -> [1,0,0]`, `C -> [0,1,0]`). ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o v·ªÅ m·∫∑t to√°n h·ªçc r·∫±ng kh√¥ng c√≥ m·ªëi quan h·ªá th·ª© t·ª± n√†o gi·ªØa c√°c h·∫°ng m·ª•c. ƒê√¢y l√† c√°ch bi·ªÉu di·ªÖn ch√≠nh x√°c nh·∫•t cho d·ªØ li·ªáu ƒë·ªãnh danh.

##### **b. Label Encoding**
* **√ù t∆∞·ªüng:** √Ånh x·∫° m·ªói h·∫°ng m·ª•c th√†nh m·ªôt s·ªë nguy√™n duy nh·∫•t (`S -> 0`, `C -> 1`, `Q -> 2`).
* **V·∫•n ƒë·ªÅ to√°n h·ªçc:** Vi·ªác n√†y t·∫°o ra m·ªôt m·ªëi quan h·ªá th·ª© t·ª± gi·∫£ t·∫°o (`Q > C > S`). C√°c m√¥ h√¨nh c√≥ th·ªÉ di·ªÖn gi·∫£i sai v·ªÅ m·ªëi quan h·ªá n√†y, do ƒë√≥ ch·ªâ n√™n d√πng k·ªπ thu·∫≠t n√†y cho bi·∫øn m·ª•c ti√™u `y` ho·∫∑c c√°c ƒë·∫∑c tr∆∞ng c√≥ th·ª© t·ª± t·ª± nhi√™n (v√≠ d·ª•: `["K√©m", "Trung b√¨nh", "T·ªët"]`).

#### **2. Chu·∫©n h√≥a ƒê·∫∑c tr∆∞ng (Feature Scaling)**

##### **a. Standardization (Chu·∫©n h√≥a Z-score)**
* **M·ª•c ti√™u:** Bi·∫øn ƒë·ªïi d·ªØ li·ªáu ƒë·ªÉ c√≥ **trung b√¨nh $\mu=0$** v√† **ƒë·ªô l·ªách chu·∫©n $\sigma=1$**.
* **C√¥ng th·ª©c:** $z = \frac{x - \mu}{\sigma}$
* **ƒê·∫∑c t√≠nh:** Kh√¥ng gi·ªõi h·∫°n gi√° tr·ªã trong m·ªôt kho·∫£ng c·ª• th·ªÉ, √≠t nh·∫°y c·∫£m v·ªõi outliers. ƒê√¢y l√† ph∆∞∆°ng ph√°p chu·∫©n h√≥a ph·ªï bi·∫øn nh·∫•t.

##### **b. Normalization (B√¨nh th∆∞·ªùng h√≥a Min-Max)**
* **M·ª•c ti√™u:** Co gi√£n d·ªØ li·ªáu ƒë·ªÉ n√≥ n·∫±m trong m·ªôt kho·∫£ng x√°c ƒë·ªãnh, th∆∞·ªùng l√† **[0, 1]**.
* **C√¥ng th·ª©c:** $x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}}$
* **ƒê·∫∑c t√≠nh:** H·ªØu √≠ch cho c√°c thu·∫≠t to√°n y√™u c·∫ßu ƒë·∫ßu v√†o trong kho·∫£ng nh·ªè (v√≠ d·ª•: m·∫°ng n∆°-ron), nh∆∞ng r·∫•t nh·∫°y c·∫£m v·ªõi outliers.

---

### **Tri·ªÉn khai & Ph√¢n t√≠ch Code**

Ch√∫ng ta s·ª≠ d·ª•ng `ColumnTransformer` ƒë·ªÉ √°p d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi kh√°c nhau l√™n c√°c c·ªôt kh√°c nhau m·ªôt c√°ch an to√†n.

    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.compose import ColumnTransformer

    df = pd.read_csv('titanic.csv')
    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)
    df['Age'].fillna(df['Age'].median(), inplace=True)
    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
    df.dropna(inplace=True)

    X = df.drop('Survived', axis=1)
    y = df['Survived']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']
    categorical_features = ['Pclass', 'Sex', 'Embarked']

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(), categorical_features)
        ])

    X_train_processed = preprocessor.fit_transform(X_train)
    X_test_processed = preprocessor.transform(X_test)
    
    print(f"K√≠ch th∆∞·ªõc X_train ban ƒë·∫ßu: {X_train.shape}")
    print(f"K√≠ch th∆∞·ªõc X_train sau x·ª≠ l√Ω: {X_train_processed.shape}")

---

### **Ph√¢n t√≠ch Chuy√™n s√¢u**

* **`fit_transform` vs. `transform`:** ƒê√¢y l√† quy t·∫Øc c·ª±c k·ª≥ quan tr·ªçng ƒë·ªÉ **tr√°nh r√≤ r·ªâ d·ªØ li·ªáu**. `.fit_transform()` ƒë∆∞·ª£c d√πng tr√™n t·∫≠p train ƒë·ªÉ **h·ªçc** c√°c tham s·ªë (v√≠ d·ª•: `mean`, `std`) v√† √°p d·ª•ng bi·∫øn ƒë·ªïi. `.transform()` ƒë∆∞·ª£c d√πng tr√™n t·∫≠p test ch·ªâ ƒë·ªÉ **√°p d·ª•ng** ph√©p bi·∫øn ƒë·ªïi v·ªõi c√°c tham s·ªë ƒë√£ h·ªçc t·ª´ t·∫≠p train, m√¥ ph·ªèng ƒë√∫ng quy tr√¨nh th·ª±c t·∫ø.

| K·ªπ thu·∫≠t             | ∆Øu ƒëi·ªÉm                                                                           | Nh∆∞·ª£c ƒëi·ªÉm / C·∫°m b·∫´y                                              |
|:---------------------|:----------------------------------------------------------------------------------|:------------------------------------------------------------------|
| **One-Hot Encoding** | - Lo·∫°i b·ªè ho√†n to√†n quan h·ªá th·ª© t·ª± gi·∫£ t·∫°o.<br>- An to√†n cho h·∫ßu h·∫øt c√°c m√¥ h√¨nh. | - G√¢y ra "l·ªùi nguy·ªÅn s·ªë chi·ªÅu" n·∫øu h·∫°ng m·ª•c c√≥ qu√° nhi·ªÅu gi√° tr·ªã. |
| **Standardization**  | - √çt b·ªã ·∫£nh h∆∞·ªüng b·ªüi outliers.<br>- Ph·ªï bi·∫øn nh·∫•t.                               | - Kh√¥ng gi·ªõi h·∫°n d·ªØ li·ªáu trong m·ªôt kho·∫£ng nh·ªè.                    |
| **Normalization**    | - ƒê·∫£m b·∫£o d·ªØ li·ªáu n·∫±m trong kho·∫£ng [0, 1], t·ªët cho m·∫°ng n∆°-ron.                   | - C·ª±c k·ª≥ nh·∫°y c·∫£m v·ªõi outliers.                                   |

---

### **‚úçÔ∏è B√†i th·ª±c h√†nh:**

S·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu `titanic` v√† c√°c t·∫≠p `X_train`, `X_test` ƒë√£ ƒë∆∞·ª£c t·∫°o trong b√†i h·ªçc.

1.  **So s√°nh StandardScaler v√† MinMaxScaler:**
    * L·∫•y ri√™ng c·ªôt `Fare` t·ª´ `X_train`.
    * Import `StandardScaler` v√† `MinMaxScaler` t·ª´ `sklearn.preprocessing`.
    * √Åp d·ª•ng `StandardScaler` cho c·ªôt n√†y v√† in ra 5 gi√° tr·ªã ƒë·∫ßu ti√™n.
    * √Åp d·ª•ng `MinMaxScaler` cho c·ªôt n√†y v√† in ra 5 gi√° tr·ªã ƒë·∫ßu ti√™n.
    * Quan s√°t v√† nh·∫≠n x√©t s·ª± kh√°c bi·ªát v·ªÅ kho·∫£ng gi√° tr·ªã c·ªßa k·∫øt qu·∫£.

2.  **K·ªπ thu·∫≠t ƒê·∫∑c tr∆∞ng Th·ªß c√¥ng (Manual Feature Engineering):**
    * Trong `X_train`, c·ªôt `Name` ch·ª©a c√°c ch·ª©c danh (Mr., Mrs., Miss., Master., Dr., etc.). Ch·ª©c danh n√†y c√≥ th·ªÉ l√† m·ªôt ƒë·∫∑c tr∆∞ng h·ªØu √≠ch.
    * Vi·∫øt m·ªôt h√†m `extract_title(name)` nh·∫≠n v√†o m·ªôt t√™n v√† tr·∫£ v·ªÅ ch·ª©c danh. **G·ª£i √Ω:** Ch·ª©c danh th∆∞·ªùng n·∫±m gi·ªØa "," v√† ".". B·∫°n c√≥ th·ªÉ d√πng `.split(',')` r·ªìi `.split('.')`.
    * √Åp d·ª•ng h√†m n√†y l√™n c·ªôt `Name` c·ªßa c·∫£ `X_train` v√† `X_test` ƒë·ªÉ t·∫°o ra m·ªôt c·ªôt m·ªõi t√™n l√† `Title`.
    * In ra c√°c gi√° tr·ªã duy nh·∫•t v√† s·ªë l∆∞·ª£ng c·ªßa ch√∫ng trong c·ªôt `Title` m·ªõi t·∫°o. **G·ª£i √Ω:** d√πng ph∆∞∆°ng th·ª©c `.value_counts()`.