# Giai đoạn 4: Nhập môn Học Máy và các Nguyên lý Cốt lõi
## Bài 4.5: Huấn luyện & Đánh giá Mô hình Phân loại

### **🎯 Mục tiêu bài học:**
1.  Hiểu quy trình huấn luyện và dự đoán cơ bản (`.fit()`, `.predict()`).
2.  Nắm vững **Ma trận nhầm lẫn (Confusion Matrix)**, nền tảng của mọi chỉ số đánh giá.
3.  Phân tích sâu về sự đánh đổi giữa **Precision** và **Recall**.
4.  Biết cách sử dụng các chỉ số tổng hợp như **F1-Score** và **AUC**.

---

### **Bối cảnh & Tầm quan trọng**

Sau khi đã chuẩn bị dữ liệu một cách cẩn thận, đây là "khoảnh khắc của sự thật". Chúng ta sẽ đưa dữ liệu đó cho mô hình để nó học. Nhưng việc học xong không có ý nghĩa nếu chúng ta không biết cách đánh giá.

Một nhà khoa học dữ liệu không thể chỉ nói "mô hình của tôi chạy tốt". Họ phải chứng minh điều đó bằng những con số cụ thể. Bài học này sẽ cung cấp cho bạn bộ công cụ để "định lượng" hiệu năng của một mô hình phân loại, giúp bạn so sánh các thuật toán khác nhau và chọn ra cái tốt nhất.

---

### **Lý thuyết Cốt lõi & Triển khai**

#### **1. Quy trình `fit` và `predict`**

* **`.fit(X_train, y_train)`:** Đây là quá trình **huấn luyện**. Chúng ta đưa cho mô hình cả "đề bài" (`X_train`) và "đáp án" (`y_train`). Mô hình sẽ cố gắng tìm ra quy luật nội tại để ánh xạ từ `X` sang `y`. Về mặt kỹ thuật, đây là lúc thuật toán tối ưu hóa (như Gradient Descent) hoạt động để tìm ra các tham số tốt nhất.
* **`.predict(X_test)`:** Đây là quá trình **dự đoán**. Chúng ta chỉ đưa cho mô hình "đề bài" mới (`X_test`) mà nó chưa từng thấy, và yêu cầu nó đưa ra "đáp án" dự đoán.


    # Code ví dụ (sử dụng dữ liệu đã xử lý từ bài trước)
    from sklearn.linear_model import LogisticRegression

    # Giả sử X_train_processed và X_test_processed đã có
    # 1. Khởi tạo mô hình
    model = LogisticRegression(random_state=42)

    # 2. Huấn luyện mô hình
    model.fit(X_train_processed, y_train)

    # 3. Đưa ra dự đoán trên tập test
    y_pred = model.predict(X_test_processed)

#### **2. Ma trận nhầm lẫn (Confusion Matrix)**

Đây là cách tốt nhất để xem xét chi tiết kết quả dự đoán. Nó là một bảng 2x2 so sánh giữa **Giá trị Thực tế** và **Giá trị Dự đoán**.



* **True Positive (TP):** Thực tế là 1, dự đoán là 1 (Dự đoán đúng người sống sót).
* **True Negative (TN):** Thực tế là 0, dự đoán là 0 (Dự đoán đúng người tử vong).
* **False Positive (FP) - Lỗi Loại I:** Thực tế là 0, dự đoán là 1 (Dự đoán nhầm người tử vong thành sống sót).
* **False Negative (FN) - Lỗi Loại II:** Thực tế là 1, dự đoán là 0 (Dự đoán nhầm người sống sót thành tử vong).


    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.title("Ma trận Nhầm lẫn")
    plt.show()

---

### **Phân tích Chuyên sâu: Các Chỉ số Đánh giá**

Từ 4 giá trị trong Ma trận nhầm lẫn, chúng ta có thể tính ra các chỉ số quan trọng.

#### **1. Accuracy (Độ chính xác)**
* **Công thức:** `(TP + TN) / (Tất cả)`
* **Ý nghĩa:** Tỷ lệ phần trăm số điểm được dự đoán đúng trên tổng số điểm.
* **Cạm bẫy:** Rất dễ gây hiểu lầm khi dữ liệu bị **mất cân bằng**. Ví dụ, nếu 95% email là không spam, một mô hình ngu ngốc chỉ cần dự đoán "không spam" cho mọi email là đã đạt Accuracy 95%, nhưng nó hoàn toàn vô dụng.

#### **2. Precision (Độ chuẩn)**
* **Công thức:** `TP / (TP + FP)`
* **Ý nghĩa:** Trong số tất cả các lần mô hình dự đoán là "Positve" (ví dụ: Sống sót), có bao nhiêu lần là đúng?
* **Khi nào quan trọng?** Khi bạn muốn **tránh sai lầm False Positive**.
    * *Ví dụ:* Lọc email spam. Một False Positive (email quan trọng bị cho vào hòm spam) là rất tệ. Chúng ta cần Precision cao.

#### **3. Recall (Độ bao phủ / Độ nhạy)**
* **Công thức:** `TP / (TP + FN)`
* **Ý nghĩa:** Trong số tất cả các trường hợp thực sự là "Positive" trong thực tế, mô hình tìm ra được bao nhiêu phần trăm?
* **Khi nào quan trọng?** Khi bạn muốn **tránh sai lầm False Negative**.
    * *Ví dụ:* Chẩn đoán bệnh ung thư. Một False Negative (bỏ sót bệnh nhân) là một thảm họa. Chúng ta cần Recall cao.

#### **4. F1-Score**
* **Công thức:** `2 * (Precision * Recall) / (Precision + Recall)`
* **Ý nghĩa:** Là trung bình điều hòa của Precision và Recall. Nó là một chỉ số duy nhất để đo lường hiệu năng khi bạn cần cân bằng giữa cả hai.


    # Lấy báo cáo chi tiết
    from sklearn.metrics import classification_report
    print(classification_report(y_test, y_pred))

---

### **✍️ Bài thực hành:**

1.  **Phân tích sự Đánh đổi:**
    * **Tình huống A:** Bạn đang xây dựng một mô hình AI để duyệt các video trên một nền tảng cho trẻ em và tự động gỡ xuống các video có nội dung không phù hợp. Trong trường hợp này, giữa **Precision** và **Recall**, bạn sẽ ưu tiên chỉ số nào hơn? Hãy giải thích tại sao. (Gợi ý: "Positive" ở đây là "video không phù hợp". Hãy nghĩ xem False Positive và False Negative có nghĩa là gì trong tình huống này).
2.  **Huấn luyện và Đánh giá một mô hình khác:**
    * Import `RandomForestClassifier` từ `sklearn.ensemble`.
    * Huấn luyện một mô hình Random Forest trên cùng bộ dữ liệu `X_train_processed` và `y_train`.
    * Đưa ra dự đoán trên `X_test_processed`.
    * In ra `classification_report` và `confusion_matrix` cho mô hình Random Forest. So sánh kết quả của nó (đặc biệt là F1-score) với mô hình `LogisticRegression` đã làm trong bài. Bạn thấy mô hình nào hoạt động tốt hơn?