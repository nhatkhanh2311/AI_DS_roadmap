# Giai đoạn 5: Đi sâu vào các Thuật toán Học Máy Kinh điển
## Bài 5.10: Tối ưu hóa Lấy cảm hứng từ Tự nhiên - Thuật toán Di truyền (GA)

### **🎯 Mục tiêu bài học:**
1.  Hiểu tư duy cốt lõi của **Thuật toán Di truyền (Genetic Algorithm)** dựa trên quá trình chọn lọc tự nhiên.
2.  Nắm vững 5 bước của quy trình tiến hóa: Khởi tạo, Đánh giá, Chọn lọc, Lai ghép, và Đột biến.
3.  Hiểu rõ khái niệm **tối ưu hóa phi đạo hàm (gradient-free optimization)** và tại sao nó quan trọng.

---

### **Bối cảnh & Tầm quan trọng**

Cho đến nay, phương pháp tối ưu hóa chính mà chúng ta biết là **Gradient Descent**. Nó hoạt động tuyệt vời, nhưng có một yêu cầu bắt buộc: hàm mất mát phải "mượt" và có thể tính được đạo hàm (để chúng ta biết "hướng dốc" mà đi xuống).

Nhưng điều gì sẽ xảy ra nếu bài toán tối ưu hóa của chúng ta:
* Không có đạo hàm (ví dụ: tối ưu hóa số lượng cây trong Random Forest)?
* Có quá nhiều "đáy thung lũng" (cực tiểu cục bộ) mà Gradient Descent có thể bị mắc kẹt?

Thuật toán Di truyền (GA) ra đời để giải quyết những vấn đề này. Nó là một thuật toán **tối ưu hóa phi đạo hàm** (gradient-free), mô phỏng lại quá trình tiến hóa và chọn lọc tự nhiên của Darwin.

**Analogy:** Nếu Gradient Descent là một người leo núi đơn độc, cẩn thận đi xuống dốc, thì Thuật toán Di truyền giống như thả 100 người lính dù xuống ngọn núi, để họ tự sinh tồn, những người khỏe nhất sẽ sinh con, và qua nhiều thế hệ, con cháu của họ sẽ tập trung tại điểm thấp nhất.

---

### **Lý thuyết Cốt lõi: 5 bước của Thuật toán Tiến hóa**

GA làm việc với một "quần thể" (population) gồm nhiều "cá thể" (individuals). Mỗi cá thể là một **giải pháp ứng cử viên** cho bài toán.

#### **1. Khởi tạo (Initialization)**
Tạo ra một quần thể ban đầu (ví dụ: 100 cá thể) một cách ngẫu nhiên. Mỗi cá thể là một bộ tham số $\theta$ ngẫu nhiên.

#### **2. Đánh giá Độ thích nghi (Fitness Evaluation)**
Đánh giá "sức khỏe" của từng cá thể bằng một **hàm thích nghi (fitness function)**. Trong học máy, hàm này thường là **nghịch đảo của hàm mất mát** (ví dụ: 1/MSE, vì chúng ta muốn tối đa hóa sự thích nghi). Cá thể nào có lỗi thấp nhất sẽ có độ thích nghi cao nhất.

#### **3. Chọn lọc (Selection)**
Chọn ra những cá thể "khỏe mạnh nhất" (có độ thích nghi cao nhất) để làm "cha mẹ" cho thế hệ tiếp theo. Những cá thể yếu sẽ bị loại bỏ.

#### **4. Lai ghép (Crossover)**
Tạo ra "con cái" (thế hệ mới) bằng cách kết hợp "gen" (các phần của giải pháp) từ hai "cha mẹ" đã được chọn lọc. Ví dụ, lấy nửa đầu tham số từ cha và nửa sau từ mẹ. Mục đích là để kết hợp những đặc điểm tốt của các giải pháp tốt.

#### **5. Đột biến (Mutation)**
Thay đổi ngẫu nhiên một vài "gen" của con cái (ví dụ: thay đổi ngẫu nhiên một vài giá trị tham số). Mục đích là để duy trì sự đa dạng trong quần thể và giúp thuật toán **thoát khỏi các cực tiểu cục bộ**.

Sau đó, quần thể mới này sẽ thay thế quần thể cũ, và toàn bộ quy trình (Bước 2 đến 5) được lặp lại qua nhiều thế hệ, cho đến khi chúng ta tìm thấy một giải pháp đủ tốt.

---

### **Phân tích Chuyên sâu**

* **Gradient-Free:** Lợi thế lớn nhất là GA không cần bất kỳ thông tin nào về đạo hàm. Nó chỉ cần biết một giải pháp "tốt" hay "tệ" thông qua hàm thích nghi.
* **Tìm kiếm Toàn cục (Global Search):** Nhờ vào tính ngẫu nhiên của Đột biến, GA có khả năng "nhảy" ra khỏi các cực tiểu cục bộ để tìm kiếm cực tiểu toàn cục tốt hơn (điều mà Gradient Descent thường xuyên thất bại).

* **So sánh GA và Gradient Descent:**

| Tiêu chí          | Gradient Descent                       | Thuật toán Di truyền (GA)                         |
|:------------------|:---------------------------------------|:--------------------------------------------------|
| **Yêu cầu**       | Hàm mất mát phải liên tục, có đạo hàm. | Chỉ cần một hàm đánh giá (fitness).               |
| **Cách tìm kiếm** | Cục bộ (Local) - đi theo độ dốc.       | Toàn cục (Global) - tìm kiếm song song nhiều nơi. |
| **Kết quả**       | Hội tụ về một cực tiểu cục bộ.         | Có khả năng tìm ra cực tiểu toàn cục.             |
| **Chi phí**       | Tương đối nhanh.                       | Rất tốn kém (phải đánh giá cả một quần thể).      |

---

### **Triển khai & Phân tích Code**

Viết một thuật toán GA từ đầu khá phức tạp, nhưng chúng ta có thể sử dụng các thư viện như `geneticalgorithm`.

    # Bạn cần cài đặt thư viện: pip install geneticalgorithm
    from geneticalgorithm import geneticalgorithm as ga
    import numpy as np

    def complex_function(X):
        """Hàm số phức tạp có nhiều cực tiểu cục bộ."""
        # Đây là hàm chúng ta muốn tìm giá trị nhỏ nhất (minimum)
        return np.sum(X**2 + 10*np.sin(X))

    # Định nghĩa "biên" (boundaries) cho các biến của chúng ta.
    # Giả sử chúng ta tìm 3 biến (3 chiều), mỗi biến trong khoảng [-10, 10]
    varbound = np.array([[-10, 10]] * 3)

    # Khởi tạo mô hình GA
    model = ga(function=complex_function, 
               dimension=3, 
               variable_type='real', 
               variable_boundaries=varbound)

    # Chạy thuật toán
    print("Bắt đầu chạy Thuật toán Di truyền...")
    model.run()
    
    print("Đã tìm thấy giải pháp tối ưu:")
    print(model.best_variable)
    print(f"Giá trị tối ưu (nhỏ nhất) tìm được: {model.best_function}")

---

### **✍️ Bài thực hành:**

Bài thực hành này mang tính tư duy, không cần code.

1.  **Phân tích Tình huống:**
    * Bạn đang cố gắng tìm ra **kiến trúc tốt nhất** cho một mạng nơ-ron. "Kiến trúc" ở đây bao gồm các lựa chọn rời rạc như: "dùng bao nhiêu tầng?", "mỗi tầng bao nhiêu nơ-ron?", "dùng hàm kích hoạt nào ('relu' hay 'tanh')?".
    * Tại sao **Gradient Descent** **không thể** được sử dụng để giải quyết trực tiếp bài toán tối ưu hóa này?
    * Tại sao **Thuật toán Di truyền (GA)** lại là một lựa chọn phù hợp? (Gợi ý: "Gen" của một "cá thể" trong bài toán này sẽ là gì?)