# Giai Ä‘oáº¡n 5: Äi sÃ¢u vÃ o cÃ¡c Thuáº­t toÃ¡n Há»c MÃ¡y Kinh Ä‘iá»ƒn
## BÃ i 5.7: Ensemble Methods (Pháº§n 1) - Bagging vÃ  Random Forests

### **ğŸ¯ Má»¥c tiÃªu bÃ i há»c:**
1.  Hiá»ƒu Ä‘Æ°á»£c triáº¿t lÃ½ "TrÃ­ tuá»‡ táº­p thá»ƒ" Ä‘áº±ng sau cÃ¡c phÆ°Æ¡ng phÃ¡p Ensemble.
2.  Náº¯m vá»¯ng ká»¹ thuáº­t **Bagging (Bootstrap Aggregating)**.
3.  Hiá»ƒu cÃ¡ch **Random Forest** cáº£i tiáº¿n tá»« Bagging vÃ  táº¡i sao nÃ³ lÃ  má»™t trong nhá»¯ng thuáº­t toÃ¡n hiá»‡u quáº£ nháº¥t.

---

### **Bá»‘i cáº£nh & Táº§m quan trá»ng**

ChÃºng ta vá»«a tháº¥y á»Ÿ bÃ i trÆ°á»›c ráº±ng CÃ¢y Quyáº¿t Ä‘á»‹nh ráº¥t máº¡nh máº½ nhÆ°ng láº¡i cá»±c ká»³ dá»… bá»‹ overfitting (phÆ°Æ¡ng sai cao). Náº¿u chÃºng ta chá»‰ trá»“ng má»™t cÃ¡i cÃ¢y, nÃ³ cÃ³ thá»ƒ má»c "lá»‡ch" theo nhiá»…u cá»§a máº£nh Ä‘áº¥t (dá»¯ liá»‡u huáº¥n luyá»‡n).

Váº­y náº¿u chÃºng ta trá»“ng cáº£ má»™t **khu rá»«ng (forest)**, má»—i cÃ¢y má»c trÃªn má»™t máº£nh Ä‘áº¥t hÆ¡i khÃ¡c nhau, rá»“i láº¥y Ã½ kiáº¿n trung bÃ¬nh cá»§a cáº£ khu rá»«ng thÃ¬ sao? Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng sáº½ á»•n Ä‘á»‹nh vÃ  Ä‘Ã¡ng tin cáº­y hÆ¡n ráº¥t nhiá»u. ÄÃ³ chÃ­nh lÃ  Ã½ tÆ°á»Ÿng cá»‘t lÃµi cá»§a Random Forest.

CÃ¡c phÆ°Æ¡ng phÃ¡p Ensemble thÆ°á»ng xuyÃªn lÃ  nhá»¯ng thuáº­t toÃ¡n chiáº¿n tháº¯ng trong cÃ¡c cuá»™c thi khoa há»c dá»¯ liá»‡u vÃ  lÃ  lá»±a chá»n hÃ ng Ä‘áº§u cho nhiá»u bÃ i toÃ¡n dá»¯ liá»‡u cÃ³ cáº¥u trÃºc.

---

### **LÃ½ thuyáº¿t Cá»‘t lÃµi & Ká»¹ thuáº­t**

#### **1. Bagging (Bootstrap Aggregating)**

Bagging lÃ  má»™t ká»¹ thuáº­t ensemble chung, hoáº¡t Ä‘á»™ng theo 2 bÆ°á»›c:

1.  **Bootstrap (Láº¥y máº«u cÃ³ hoÃ n láº¡i):** Tá»« táº­p huáº¥n luyá»‡n ban Ä‘áº§u cÃ³ `N` máº«u, chÃºng ta táº¡o ra `B` bá»™ dá»¯ liá»‡u con má»›i, má»—i bá»™ cÅ©ng cÃ³ `N` máº«u. CÃ¡c bá»™ dá»¯ liá»‡u con nÃ y Ä‘Æ°á»£c táº¡o báº±ng cÃ¡ch **láº¥y máº«u ngáº«u nhiÃªn cÃ³ hoÃ n láº¡i**. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  má»™t máº«u gá»‘c cÃ³ thá»ƒ xuáº¥t hiá»‡n nhiá»u láº§n hoáº·c khÃ´ng xuáº¥t hiá»‡n láº§n nÃ o trong má»™t bá»™ dá»¯ liá»‡u con.
2.  **Aggregating (Tá»•ng há»£p):** Huáº¥n luyá»‡n `B` mÃ´ hÃ¬nh riÃªng biá»‡t, má»—i mÃ´ hÃ¬nh trÃªn má»™t bá»™ dá»¯ liá»‡u con. Káº¿t quáº£ cuá»‘i cÃ¹ng Ä‘Æ°á»£c tá»•ng há»£p láº¡i:
    * **BÃ i toÃ¡n PhÃ¢n loáº¡i:** Láº¥y káº¿t quáº£ theo **Ä‘a sá»‘ phiáº¿u (majority voting)**.
    * **BÃ i toÃ¡n Há»“i quy:** Láº¥y **trung bÃ¬nh** káº¿t quáº£.

Ká»¹ thuáº­t nÃ y giÃºp **giáº£m phÆ°Æ¡ng sai (variance)** cá»§a mÃ´ hÃ¬nh, lÃ m cho nÃ³ á»•n Ä‘á»‹nh vÃ  Ã­t bá»‹ overfitting hÆ¡n.

#### **2. Rá»«ng Ngáº«u nhiÃªn (Random Forest) ğŸŒ³**

Random Forest lÃ  má»™t sá»± cáº£i tiáº¿n vÃ  chuyÃªn biá»‡t hÃ³a cá»§a ká»¹ thuáº­t Bagging, sá»­ dá»¥ng CÃ¢y Quyáº¿t Ä‘á»‹nh lÃ m mÃ´ hÃ¬nh cÆ¡ sá»Ÿ.

NÃ³ thÃªm vÃ o **má»™t lá»›p ngáº«u nhiÃªn ná»¯a** so vá»›i Bagging:
* NgoÃ i viá»‡c huáº¥n luyá»‡n má»—i cÃ¢y trÃªn má»™t máº«u dá»¯ liá»‡u con ngáº«u nhiÃªn (Bootstrap), táº¡i **má»—i nÃºt** trong quÃ¡ trÃ¬nh xÃ¢y dá»±ng cÃ¢y, thay vÃ¬ xem xÃ©t táº¥t cáº£ cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»ƒ tÃ¬m ra cÃ¡ch chia tá»‘t nháº¥t, cÃ¢y chá»‰ Ä‘Æ°á»£c phÃ©p xem xÃ©t má»™t **táº­p con ngáº«u nhiÃªn** cá»§a cÃ¡c Ä‘áº·c trÆ°ng.

**Táº¡i sao láº¡i thÃªm sá»± ngáº«u nhiÃªn nÃ y?**
NÃ³ giÃºp lÃ m cho cÃ¡c cÃ¢y trong rá»«ng trá»Ÿ nÃªn **"Ä‘a dáº¡ng"** vÃ  **"Ã­t tÆ°Æ¡ng quan"** vá»›i nhau hÆ¡n. Náº¿u khÃ´ng cÃ³ bÆ°á»›c nÃ y, táº¥t cáº£ cÃ¡c cÃ¢y cÃ³ thá»ƒ Ä‘á»u chá»n má»™t vÃ i Ä‘áº·c trÆ°ng máº¡nh nháº¥t Ä‘á»ƒ chia á»Ÿ cÃ¡c nÃºt Ä‘áº§u tiÃªn, lÃ m cho chÃºng trá»Ÿ nÃªn khÃ¡ giá»‘ng nhau. Báº±ng cÃ¡ch buá»™c má»—i cÃ¢y chá»‰ Ä‘Æ°á»£c xem má»™t vÃ i Ä‘áº·c trÆ°ng táº¡i má»™t thá»i Ä‘iá»ƒm, chÃºng ta khuyáº¿n khÃ­ch cÃ¡c cÃ¢y khÃ¡c nhau há»c cÃ¡c quy luáº­t khÃ¡c nhau tá»« dá»¯ liá»‡u.

---

### **Triá»ƒn khai & PhÃ¢n tÃ­ch Code**

ChÃºng ta sáº½ so sÃ¡nh hiá»‡u nÄƒng cá»§a má»™t CÃ¢y Quyáº¿t Ä‘á»‹nh Ä‘Æ¡n láº» vá»›i má»™t Random Forest.

    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score

    # Chuáº©n bá»‹ dá»¯ liá»‡u (tÆ°Æ¡ng tá»± cÃ¡c bÃ i trÆ°á»›c)
    df = pd.read_csv('titanic.csv')
    df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)
    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)
    df['Age'] = df['Age'].fillna(df['Age'].median())
    df.dropna(inplace=True)
    X = df.drop('Survived', axis=1)
    y = df['Survived']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- 1. CÃ¢y Quyáº¿t Ä‘á»‹nh Ä‘Æ¡n láº» (bá»‹ overfitting) ---
    single_tree = DecisionTreeClassifier(random_state=42)
    single_tree.fit(X_train, y_train)
    y_pred_tree = single_tree.predict(X_test)
    acc_tree = accuracy_score(y_test, y_pred_tree)
    print(f"Accuracy cá»§a CÃ¢y Quyáº¿t Ä‘á»‹nh Ä‘Æ¡n láº»: {acc_tree:.4f}")

    # --- 2. Random Forest ---
    # n_estimators: sá»‘ lÆ°á»£ng cÃ¢y trong rá»«ng
    forest = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    forest.fit(X_train, y_train)
    y_pred_forest = forest.predict(X_test)
    acc_forest = accuracy_score(y_test, y_pred_forest)
    print(f"Accuracy cá»§a Random Forest: {acc_forest:.4f}")

---

### **PhÃ¢n tÃ­ch ChuyÃªn sÃ¢u**

* **Æ¯u Ä‘iá»ƒm cá»§a Random Forest:**
    * **Hiá»‡u nÄƒng cao:** ThÆ°á»ng cho káº¿t quáº£ ráº¥t tá»‘t mÃ  khÃ´ng cáº§n tinh chá»‰nh siÃªu tham sá»‘ nhiá»u.
    * **á»”n Ä‘á»‹nh vÃ  Chá»‘ng Overfitting:** Nhá» vÃ o tÃ­nh ngáº«u nhiÃªn vÃ  viá»‡c láº¥y trung bÃ¬nh, nÃ³ Ã­t bá»‹ overfitting hÆ¡n nhiá»u so vá»›i má»™t cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘Æ¡n láº».
    * **CÃ³ thá»ƒ Ä‘o lÆ°á»ng Táº§m quan trá»ng cá»§a Äáº·c trÆ°ng:** Báº±ng cÃ¡ch xem xÃ©t má»©c Ä‘á»™ mÃ  má»—i Ä‘áº·c trÆ°ng giÃºp giáº£m Ä‘á»™ "táº¡p nham" trÃªn toÃ n bá»™ cÃ¡c cÃ¢y, Random Forest cÃ³ thá»ƒ Ä‘Æ°a ra má»™t xáº¿p háº¡ng vá» má»©c Ä‘á»™ quan trá»ng cá»§a cÃ¡c Ä‘áº·c trÆ°ng (`.feature_importances_`).

* **NhÆ°á»£c Ä‘iá»ƒm:**
    * **Máº¥t tÃ­nh diá»…n giáº£i:** NÃ³ trá»Ÿ thÃ nh má»™t mÃ´ hÃ¬nh **"há»™p Ä‘en" (black-box)**. ChÃºng ta khÃ´ng thá»ƒ dá»… dÃ ng diá»…n giáº£i má»™t quyáº¿t Ä‘á»‹nh dá»±a trÃªn hÃ ng trÄƒm cÃ¢y nhÆ° vá»›i má»™t cÃ¢y duy nháº¥t.
    * **Tá»‘n tÃ i nguyÃªn hÆ¡n:** Cáº§n nhiá»u thá»i gian vÃ  bá»™ nhá»› hÆ¡n Ä‘á»ƒ huáº¥n luyá»‡n so vá»›i má»™t cÃ¢y Ä‘Æ¡n láº».

---

### **âœï¸ BÃ i thá»±c hÃ nh:**

Sá»­ dá»¥ng bá»™ dá»¯ liá»‡u `Boston Housing` vÃ  cÃ¡c táº­p dá»¯ liá»‡u Ä‘Ã£ chia (`X_train`, `X_test`, `y_train`, `y_test`).

1.  **Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh Há»“i quy:**
    * Import `DecisionTreeRegressor` vÃ  `RandomForestRegressor`.
    * Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh `DecisionTreeRegressor` (vá»›i `random_state=42`).
    * Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh `RandomForestRegressor` (vá»›i `n_estimators=100`, `random_state=42`).

2.  **ÄÃ¡nh giÃ¡ vÃ  So sÃ¡nh:**
    * ÄÃ¡nh giÃ¡ cáº£ hai mÃ´ hÃ¬nh trÃªn táº­p test báº±ng chá»‰ sá»‘ **RMSE**.
    * So sÃ¡nh káº¿t quáº£. Báº¡n cÃ³ tháº¥y Random Forest Regressor cho sai sá»‘ tháº¥p hÆ¡n (tá»‘t hÆ¡n) khÃ´ng?

3.  **(TÃ¹y chá»n) Xem xÃ©t Táº§m quan trá»ng cá»§a Äáº·c trÆ°ng:**
    * Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh `RandomForestRegressor`, truy cáº­p thuá»™c tÃ­nh `.feature_importances_` cá»§a nÃ³.
    * Táº¡o má»™t Pandas Series Ä‘á»ƒ hiá»ƒn thá»‹ táº§m quan trá»ng cá»§a má»—i Ä‘áº·c trÆ°ng cÃ¹ng vá»›i tÃªn cá»§a nÃ³. Äáº·c trÆ°ng nÃ o cÃ³ áº£nh hÆ°á»Ÿng lá»›n nháº¥t Ä‘áº¿n viá»‡c dá»± Ä‘oÃ¡n giÃ¡ nhÃ ?