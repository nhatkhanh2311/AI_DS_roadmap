# Giai ƒëo·∫°n 5: ƒêi s√¢u v√†o c√°c Thu·∫≠t to√°n H·ªçc M√°y Kinh ƒëi·ªÉn
## B√†i 5.4: H·ªçc d·ª±a tr√™n kho·∫£ng c√°ch - K-Nearest Neighbors (KNN)

### **üéØ M·ª•c ti√™u b√†i h·ªçc:**
1.  Hi·ªÉu ƒë∆∞·ª£c t∆∞ duy tr·ª±c quan c·ªßa thu·∫≠t to√°n **K-H√†ng x√≥m g·∫ßn nh·∫•t (K-Nearest Neighbors - KNN)**.
2.  Ph√¢n t√≠ch t·∫ßm quan tr·ªçng c·ªßa vi·ªác l·ª±a ch·ªçn si√™u tham s·ªë **`k`** v√† **th∆∞·ªõc ƒëo kho·∫£ng c√°ch**.
3.  Hi·ªÉu t·∫°i sao **Chu·∫©n h√≥a ƒê·∫∑c tr∆∞ng (Feature Scaling)** l√† b∆∞·ªõc b·∫Øt bu·ªôc ƒë·ªëi v·ªõi KNN.
4.  Tri·ªÉn khai KNN cho c·∫£ b√†i to√°n ph√¢n lo·∫°i v√† h·ªìi quy.

---

### **B·ªëi c·∫£nh & T·∫ßm quan tr·ªçng**

KNN l√† m·ªôt trong nh·ªØng thu·∫≠t to√°n ƒë∆°n gi·∫£n v√† d·ªÖ hi·ªÉu nh·∫•t trong Machine Learning. Tri·∫øt l√Ω c·ªßa n√≥ r·∫•t ƒë·ªùi th∆∞·ªùng: "Ng∆∞u t·∫ßm ng∆∞u, m√£ t·∫ßm m√£" (Birds of a feather flock together). ƒê·ªÉ x√°c ƒë·ªãnh m·ªôt ƒë·ªëi t∆∞·ª£ng m·ªõi, h√£y nh√¨n v√†o nh·ªØng "h√†ng x√≥m" g·∫ßn nh·∫•t c·ªßa n√≥.

D√π ƒë∆°n gi·∫£n, KNN l√† m·ªôt m√¥ h√¨nh **phi tham s·ªë (non-parametric)**, nghƒ©a l√† n√≥ kh√¥ng ƒë∆∞a ra gi·∫£ ƒë·ªãnh n√†o v·ªÅ d·∫°ng ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu. ƒêi·ªÅu n√†y l√†m cho n√≥ r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c c√°c ƒë∆∞·ªùng bi√™n quy·∫øt ƒë·ªãnh ph·ª©c t·∫°p.

---

### **L√Ω thuy·∫øt C·ªët l√µi & N·ªÅn t·∫£ng To√°n h·ªçc**

#### **1. Thu·∫≠t to√°n ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?**

ƒê·ªÉ ph√¢n lo·∫°i m·ªôt ƒëi·ªÉm d·ªØ li·ªáu m·ªõi (v√≠ d·ª•: m·ªôt ch·∫•m h·ªèi m√†u xanh l√°), KNN th·ª±c hi·ªán 3 b∆∞·ªõc:
1.  **T√≠nh Kho·∫£ng c√°ch:** T√≠nh kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm d·ªØ li·ªáu m·ªõi ƒë·∫øn **t·∫•t c·∫£** c√°c ƒëi·ªÉm trong t·∫≠p hu·∫•n luy·ªán.
2.  **T√¨m K H√†ng x√≥m:** X√°c ƒë·ªãnh **`k`** ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t (k-nearest neighbors). `k` l√† m·ªôt s·ªë nguy√™n do ch√∫ng ta l·ª±a ch·ªçn.
3.  **B·ªè phi·∫øu (Voting):** L·∫•y √Ω ki·∫øn c·ªßa `k` h√†ng x√≥m ƒë√≥. H·∫°ng m·ª•c n√†o chi·∫øm ƒëa s·ªë s·∫Ω l√† d·ª± ƒëo√°n cho ƒëi·ªÉm d·ªØ li·ªáu m·ªõi.



#### **2. Th∆∞·ªõc ƒëo Kho·∫£ng c√°ch**
Kho·∫£ng c√°ch ph·ªï bi·∫øn nh·∫•t ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† **Kho·∫£ng c√°ch Euclid (Euclidean Distance)**, v·ªÅ c∆° b·∫£n l√† c√¥ng th·ª©c t√≠nh kho·∫£ng c√°ch ƒë∆∞·ªùng th·∫≥ng gi·ªØa hai ƒëi·ªÉm trong kh√¥ng gian.

* **C√¥ng th·ª©c (2 chi·ªÅu):**
    $$ d(A, B) = \sqrt{(x_A - x_B)^2 + (y_A - y_B)^2} $$

#### **3. T·∫ßm quan tr·ªçng c·ªßa Si√™u tham s·ªë `k`**
`k` l√† si√™u tham s·ªë quan tr·ªçng nh·∫•t, quy·∫øt ƒë·ªãnh s·ª± c√¢n b·∫±ng gi·ªØa Bias v√† Variance.
* **`k` nh·ªè (v√≠ d·ª•: k=1):** M√¥ h√¨nh r·∫•t nh·∫°y c·∫£m v·ªõi nhi·ªÖu, d·ªÖ b·ªã **Overfitting**. ƒê∆∞·ªùng bi√™n quy·∫øt ƒë·ªãnh s·∫Ω r·∫•t ph·ª©c t·∫°p.
* **`k` l·ªõn:** M√¥ h√¨nh s·∫Ω "m∆∞·ª£t" h∆°n, √≠t b·ªã ·∫£nh h∆∞·ªüng b·ªüi nhi·ªÖu, nh∆∞ng n·∫øu qu√° l·ªõn c√≥ th·ªÉ b·ªã **Underfitting**.

#### **4. T·∫°i sao Chu·∫©n h√≥a ƒê·∫∑c tr∆∞ng l√† B·∫Øt bu·ªôc?**
V√¨ KNN ho·∫°t ƒë·ªông ho√†n to√†n d·ª±a tr√™n kho·∫£ng c√°ch, n·∫øu c√°c ƒë·∫∑c tr∆∞ng c√≥ thang ƒëo kh√°c nhau, ƒë·∫∑c tr∆∞ng c√≥ thang ƒëo l·ªõn h∆°n s·∫Ω ho√†n to√†n "√°t v√≠a" c√°c ƒë·∫∑c tr∆∞ng kh√°c trong vi·ªác t√≠nh to√°n kho·∫£ng c√°ch.

* **V√≠ d·ª•:** M·ªôt ƒë·∫∑c tr∆∞ng l√† `L∆∞∆°ng` (h√†ng ch·ª•c tri·ªáu) v√† m·ªôt ƒë·∫∑c tr∆∞ng l√† `S·ªë con` (0-5). S·ª± kh√°c bi·ªát 10 tri·ªáu trong l∆∞∆°ng s·∫Ω l·ªõn h∆°n r·∫•t nhi·ªÅu so v·ªõi s·ª± kh√°c bi·ªát 2 ƒë·ª©a con, l√†m cho ƒë·∫∑c tr∆∞ng `S·ªë con` g·∫ßn nh∆∞ v√¥ nghƒ©a.
* **Gi·∫£i ph√°p:** Lu√¥n lu√¥n ph·∫£i **Standardize** ho·∫∑c **Normalize** d·ªØ li·ªáu tr∆∞·ªõc khi ƒë∆∞a v√†o KNN.

---

### **Tri·ªÉn khai & Ph√¢n t√≠ch Code**

Ch√∫ng ta s·∫Ω th·∫•y r√µ t·∫ßm quan tr·ªçng c·ªßa vi·ªác chu·∫©n h√≥a d·ªØ li·ªáu.

    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import accuracy_score

    # Chu·∫©n b·ªã d·ªØ li·ªáu (ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω)
    df = pd.read_csv('titanic.csv')
    df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True) # One-hot encode
    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)
    df['Age'] = df['Age'].fillna(df['Age'].median())
    df.dropna(inplace=True)
    X = df.drop('Survived', axis=1)
    y = df['Survived']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- Tr∆∞·ªùng h·ª£p 1: KH√îNG Chu·∫©n h√≥a ---
    knn_unscaled = KNeighborsClassifier(n_neighbors=5)
    knn_unscaled.fit(X_train, y_train)
    y_pred_unscaled = knn_unscaled.predict(X_test)
    acc_unscaled = accuracy_score(y_test, y_pred_unscaled)
    print(f"Accuracy c·ªßa KNN khi CH∆ØA chu·∫©n h√≥a: {acc_unscaled:.4f}")

    # --- Tr∆∞·ªùng h·ª£p 2: C√ì Chu·∫©n h√≥a ---
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    knn_scaled = KNeighborsClassifier(n_neighbors=5)
    knn_scaled.fit(X_train_scaled, y_train)
    y_pred_scaled = knn_scaled.predict(X_test_scaled)
    acc_scaled = accuracy_score(y_test, y_pred_scaled)
    print(f"Accuracy c·ªßa KNN khi ƒê√É chu·∫©n h√≥a: {acc_scaled:.4f}")

---

### **Ph√¢n t√≠ch Chuy√™n s√¢u**

* **M√¥ h√¨nh "L∆∞·ªùi bi·∫øng" (Lazy Learner):** KNN l√† m·ªôt thu·∫≠t to√°n "l∆∞·ªùi". N√≥ kh√¥ng "h·ªçc" m·ªôt h√†m s·ªë n√†o c·∫£ trong giai ƒëo·∫°n `.fit()`. To√†n b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán ch·ªâ ƒë∆°n gi·∫£n l√† ƒë∆∞·ª£c l∆∞u v√†o b·ªô nh·ªõ. To√†n b·ªô c√¥ng vi·ªác t√≠nh to√°n (t√≠nh kho·∫£ng c√°ch) ƒë∆∞·ª£c d·ªìn v√†o l√∫c `.predict()`.
* **∆Øu ƒëi·ªÉm:** Hu·∫•n luy·ªán c·ª±c nhanh (g·∫ßn nh∆∞ t·ª©c th√¨). R·∫•t d·ªÖ hi·ªÉu v√† tri·ªÉn khai.
* **Nh∆∞·ª£c ƒëi·ªÉm:**
    * **D·ª± ƒëo√°n ch·∫≠m v√† t·ªën b·ªô nh·ªõ:** Ph·∫£i l∆∞u to√†n b·ªô d·ªØ li·ªáu v√† t√≠nh to√°n v·ªõi m·ªçi ƒëi·ªÉm khi c√≥ d·ª± ƒëo√°n m·ªõi.
    * **"L·ªùi nguy·ªÅn c·ªßa s·ªë chi·ªÅu" (Curse of Dimensionality):** Ho·∫°t ƒë·ªông k√©m hi·ªáu qu·∫£ khi s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng r·∫•t l·ªõn, v√¨ kh√°i ni·ªám "kho·∫£ng c√°ch" tr·ªü n√™n k√©m √Ω nghƒ©a trong kh√¥ng gian nhi·ªÅu chi·ªÅu.

---

### **‚úçÔ∏è B√†i th·ª±c h√†nh:**

1.  **T√¨m `k` t·ªëi ∆∞u:**
    * S·ª≠ d·ª•ng d·ªØ li·ªáu **ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a** (`X_train_scaled`, `X_test_scaled`).
    * Vi·∫øt m·ªôt v√≤ng l·∫∑p `for` ƒë·ªÉ th·ª≠ c√°c gi√° tr·ªã `k` t·ª´ 1 ƒë·∫øn 20.
    * V·ªõi m·ªói gi√° tr·ªã `k`, h√£y hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh `KNeighborsClassifier` v√† t√≠nh `accuracy` tr√™n t·∫≠p test.
    * In ra gi√° tr·ªã `k` n√†o cho `accuracy` cao nh·∫•t.

2.  **KNN cho H·ªìi quy:**
    * KNN c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c d√πng cho b√†i to√°n h·ªìi quy (`KNeighborsRegressor`). Thay v√¨ b·ªè phi·∫øu, n√≥ s·∫Ω l·∫•y **trung b√¨nh** gi√° tr·ªã c·ªßa `k` h√†ng x√≥m g·∫ßn nh·∫•t ƒë·ªÉ l√†m d·ª± ƒëo√°n.
    * S·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu `Boston Housing` (ƒë√£ c√≥ code load ·ªü b√†i 5.1).
    * **B∆∞·ªõc 1:** Chu·∫©n h√≥a `X_train` v√† `X_test` b·∫±ng `StandardScaler`.
    * **B∆∞·ªõc 2:** Import `KNeighborsRegressor` t·ª´ `sklearn.neighbors`.
    * **B∆∞·ªõc 3:** Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi `k=5` tr√™n d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a.
    * **B∆∞·ªõc 4:** ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng ch·ªâ s·ªë **RMSE** v√† **R-squared ($R^2$)**. So s√°nh k·∫øt qu·∫£ v·ªõi `LinearRegression`.