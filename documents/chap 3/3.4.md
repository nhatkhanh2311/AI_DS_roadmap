# Giai đoạn 3: Thu thập và Quản lý Dữ liệu
## Bài 3.4: Thu thập dữ liệu từ Web (APIs & Web Scraping)

### **🎯 Mục tiêu bài học:**
1.  Hiểu **API** là gì và cách sử dụng thư viện `requests` để lấy dữ liệu từ một API.
2.  Hiểu khái niệm **JSON** và cách xử lý dữ liệu JSON trong Python.
3.  Hiểu khái niệm cơ bản về **Web Scraping** và làm quen với thư viện `BeautifulSoup`.

---

### **1. Lấy dữ liệu qua API (Application Programming Interface)**

API là một "cổng giao tiếp" mà các nhà cung cấp dịch vụ (như Google Maps, Twitter, các trang web tin tức) tạo ra để cho phép các lập trình viên truy cập vào dữ liệu của họ một cách có cấu trúc và được cho phép. Đây là cách lấy dữ liệu từ web được ưu tiên nhất.

**Analogy:** Tưởng tượng bạn vào một nhà hàng. Thay vì chạy vào bếp (web scraping) để tự lấy đồ ăn, bạn gọi phục vụ (API) và đưa ra yêu cầu (request). Người phục vụ sẽ mang đúng món ăn (dữ liệu) ra cho bạn.

#### **a. Sử dụng thư viện `requests`**
`requests` là thư viện tiêu chuẩn để thực hiện các yêu cầu HTTP trong Python.

    import requests
    import json

    # 1. Xác định URL của API endpoint
    # API này cung cấp thông tin ngẫu nhiên về loài chó
    url = "https://dog.ceo/api/breeds/image/random"

    try:
        # 2. Gửi một yêu cầu GET đến URL
        response = requests.get(url)
        response.raise_for_status() # Báo lỗi nếu request không thành công (vd: lỗi 404, 500)

        # 3. Xử lý kết quả (thường ở định dạng JSON)
        data = response.json()
        print("--- Dữ liệu nhận được từ API ---")
        print(data)

        # 4. Trích xuất thông tin cần thiết
        image_url = data['message']
        status = data['status']
        print(f"\nLink ảnh: {image_url}")
        print(f"Trạng thái: {status}")

    except requests.exceptions.RequestException as e:
        print(f"Lỗi khi gọi API: {e}")

#### **b. Dữ liệu JSON**
**JSON (JavaScript Object Notation)** là định dạng văn bản chuẩn để trao đổi dữ liệu. Nó rất dễ cho người đọc và cho máy tính phân tích. Cấu trúc của nó gần như giống hệt với Dictionary của Python. Hàm `response.json()` sẽ tự động chuyển đổi chuỗi JSON trả về thành một Dictionary/List trong Python.

---

### **2. Web Scraping ("Cào" Dữ liệu)**

Web Scraping là quá trình tự động trích xuất dữ liệu trực tiếp từ mã HTML của một trang web. Chúng ta chỉ nên dùng cách này khi trang web đó **không cung cấp API**.

**Cảnh báo:** Luôn kiểm tra file `robots.txt` của một trang web (ví dụ: `https://example.com/robots.txt`) và các điều khoản dịch vụ để đảm bảo bạn được phép "cào" dữ liệu.

#### **a. Các công cụ cần thiết**
* **`requests`**: Để tải về nội dung HTML của trang web.
* **`BeautifulSoup4`**: Để "phân tích cú pháp" (parse) nội dung HTML đó, giúp chúng ta dễ dàng tìm kiếm và trích xuất các thẻ. (Bạn cần cài đặt: `pip install beautifulsoup4`)

#### **b. Quy trình cơ bản**

    from bs4 import BeautifulSoup

    # 1. Xác định URL của trang web cần cào
    url_to_scrape = 'https://quotes.toscrape.com/' # Một trang web được tạo ra để thực hành scraping

    try:
        # 2. Dùng requests để lấy mã HTML
        response = requests.get(url_to_scrape)
        response.raise_for_status()

        # 3. Dùng BeautifulSoup để parse HTML
        soup = BeautifulSoup(response.text, 'html.parser')

        # 4. Tìm và trích xuất thông tin
        # Ví dụ: Tìm tất cả các thẻ <span> có class là 'text'
        quotes = soup.find_all('span', class_='text')

        print("\n--- Các câu trích dẫn lấy được từ Web Scraping ---")
        for quote in quotes:
            print(f"- {quote.get_text()}")

    except requests.exceptions.RequestException as e:
        print(f"Lỗi khi truy cập trang web: {e}")

---

### **✍️ Bài thực hành:**

1.  **Làm việc với API Thời tiết:**
    * Trang web `wttr.in` cung cấp một API đơn giản để lấy thông tin thời tiết.
    * **Bước 1:** Tạo URL để lấy thông tin thời tiết của Hà Nội ở định dạng JSON: `url = "https://wttr.in/Hanoi?format=j1"`
    * **Bước 2:** Sử dụng thư viện `requests` để gọi API này.
    * **Bước 3:** Chuyển kết quả trả về thành dạng JSON.
    * **Bước 4:** Từ dữ liệu nhận được, hãy in ra thông tin về **Thời tiết hiện tại (current_condition)**, cụ thể là nhiệt độ tính theo độ C (`temp_C`) và mô tả thời tiết (`weatherDesc`).

2.  **Web Scraping Tiêu đề Tin tức:**
    * **Bước 1:** Chọn một trang báo điện tử đơn giản (ví dụ: VnExpress, Tuổi Trẻ).
    * **Bước 2:** Sử dụng `requests` để lấy nội dung HTML của trang chủ.
    * **Bước 3:** Sử dụng `BeautifulSoup` để parse HTML.
    * **Bước 4:** Dùng **"Inspect"** (Chuột phải -> Inspect) trên trình duyệt để xác định thẻ và `class` chung của các tiêu đề bài báo trên trang chủ.
    * **Bước 5:** Viết code dùng `soup.find_all()` để trích xuất và in ra 5 tiêu đề bài báo đầu tiên bạn tìm thấy.